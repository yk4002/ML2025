{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceaceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, adjusted_mutual_info_score, adjusted_rand_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23001a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "X, y = mnist[\"data\"], mnist[\"target\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eef80aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sampled images and labels with one row per class and five images per class.\n",
    "# (Source inspiration: official sklearn MNIST examples + typical MNIST visualization snippets) LINK??\n",
    "f=(15,10)\n",
    "classes = 10 #classes from 0-9\n",
    "imgs_per_class = 5\n",
    "fig, axes = plt.subplots(classes, imgs_per_class, figsize=f)\n",
    "#iterate through every class\n",
    "for mnist_dig in range(classes):\n",
    "    indexes = np.where(y==mnist_dig)[0] #check when the y values equal the digit\n",
    "    chosen = np.random.choice(indexes, imgs_per_class, replace=False) #get a bunch of images per class\n",
    "    #now iterate through the chosen ones\n",
    "    for i, idx in enumerate(chosen):\n",
    "        ax = axes[mnist_dig, i] #create two axes?\n",
    "        ax.imshow(X[idx].reshape(28, 28), cmap=\"gray\") #reshape to size of the MNIST\n",
    "        ax.axis(\"off\") #readability\n",
    "\n",
    "plt.suptitle(\"Sampled MNIST images with class labels\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4ef760",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimensionality reduction to 100 features so that training is faster\n",
    "n = 100\n",
    "scaler = StandardScaler(with_std=False)\n",
    "X_centred = scaler.fit_transform(X)\n",
    "pca = PCA(n_components=n)\n",
    "X_PCA = pca.fit_transform(X_centred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4759dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE: Scikit Silhouette Analysis for KMeans Clustering (and GMM) where it is used for one parameter - here we use it for 3!\n",
    "#use silhouette score to evaluate Kmeans. Maybe explore one more hyperparameter?\n",
    "hyperparams_k = {\n",
    "    \"n_clusters\": [10],\n",
    "    \"max_iter\": [300,400,500],\n",
    "    \"n_init\": [5, 10,15, 20] #n_init specifies how many times the K-Means algorithm will run with different centroid seeds.\n",
    "    #maybe one more\n",
    "}\n",
    "\n",
    "#progress bar setup \n",
    "total_k_runs = (\n",
    "    len(hyperparams_k[\"n_clusters\"]) *\n",
    "    len(hyperparams_k[\"max_iter\"]) *\n",
    "    len(hyperparams_k[\"n_init\"])\n",
    ")\n",
    "pbar = tqdm(total=total_k_runs, desc=\"KMeans search\")\n",
    "\n",
    "#loop through all hyperparam combinatiosn and use silhouette score as the matrix to evaluate which one is the best\n",
    "best_score_k = -1\n",
    "best_params_k = None\n",
    "for n_clusters in hyperparams_k[\"n_clusters\"]:\n",
    "    for max_iter in hyperparams_k[\"max_iter\"]:\n",
    "        for n_init in hyperparams_k[\"n_init\"]:\n",
    "            model = KMeans(n_clusters=n_clusters, max_iter=max_iter, n_init=n_init, random_state=42)\n",
    "            labels = model.fit_predict(X_PCA)\n",
    "            sil_sc = silhouette_score(X_PCA, labels)\n",
    "            if sil_sc > best_score_k:\n",
    "                best_score_k = sil_sc\n",
    "                best_params_k = {\"n_clusters\": n_clusters, \"max_iter\": max_iter, \"n_init\": n_init}\n",
    "            pbar.update(1)\n",
    "pbar.close()\n",
    "print(\"Best KMeans params:\", best_params_k)\n",
    "\n",
    "#define the model with optimised paraneters\n",
    "kmeans = KMeans(n_clusters=best_params_k[\"n_clusters\"], \n",
    "                max_iter=best_params_k[\"max_iter\"],\n",
    "                n_init=best_params_k[\"n_init\"],\n",
    "                random_state=42)\n",
    "kmeans.fit(X_PCA)\n",
    "labels_k = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06af0271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#block 5\n",
    "#GMM\n",
    "hyperparams_gmm = {\n",
    "    \"n_components\": [10], #number of clusters - ideally 10 but who knows\n",
    "    \"covariance_type\": [\"full\", \"diag\"], ##changes how clusters fitted into shapes. Spherical too simple for MNIST?\n",
    "    \"n_init\": [5,10] #how many times run with different configs\n",
    "    #maybe one more of at least 2 if not 3\n",
    "}\n",
    "\n",
    "total_g_runs = (\n",
    "    len(hyperparams_gmm[\"n_components\"]) *\n",
    "    len(hyperparams_gmm[\"covariance_type\"]) *\n",
    "    len(hyperparams_gmm[\"n_init\"])\n",
    ")\n",
    "\n",
    "pbar = tqdm(total=total_g_runs, desc=\"GMM search\")\n",
    "\n",
    "best_score_g = -1\n",
    "best_params_g = None\n",
    "\n",
    "#iterate through the loop\n",
    "for n_comp in hyperparams_gmm[\"n_components\"]:\n",
    "    for cov in hyperparams_gmm[\"covariance_type\"]:\n",
    "        for n_init in hyperparams_gmm[\"n_init\"]:\n",
    "            gmm = GaussianMixture(n_components=n_comp,covariance_type=cov,n_init=n_init,random_state=42)\n",
    "            gmm.fit(X_PCA)\n",
    "            labels = gmm.predict(X_PCA)\n",
    "            #use the silhouette score to evaluate the stuff\n",
    "            sil = silhouette_score(X_PCA, labels)\n",
    "            if sil > best_score_g:\n",
    "                best_score_g = sil\n",
    "                best_params_g = {\"n_components\": n_comp,\"covariance_type\": cov,\"n_init\": n_init}\n",
    "            pbar.update(1)\n",
    "pbar.close()\n",
    "            \n",
    "print(\"Best GMM params:\", best_params_g)\n",
    "\n",
    "#initialise models with ideal params, fit to data and then get labels\n",
    "gmm = GaussianMixture(n_components=best_params_g[\"n_components\"],\n",
    "                      covariance_type=best_params_g[\"covariance_type\"],\n",
    "                      n_init=best_params_g[\"n_init\"],\n",
    "                      random_state=42)\n",
    "gmm.fit(X_PCA)\n",
    "labels_g = gmm.predict(X_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a426e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate clustering performance of both clustering methods\n",
    "print(\"\\nKMEANS METRICS\")\n",
    "print(\"Adjusted Rand Index Kmeans:\", adjusted_rand_score(y, labels_k))\n",
    "print(\"Adjusted Mutual Info Kmeans:\", adjusted_mutual_info_score(y, labels_k))\n",
    "print(\"Silhouette Kmeans:\", silhouette_score(X_PCA, labels_k))\n",
    "\n",
    "print(\"\\nGMM METRICS\")\n",
    "print(\"Adjusted Rand Index GMM:\", adjusted_rand_score(y, labels_g))\n",
    "print(\"Adjusted Mutual Info GMM:\", adjusted_mutual_info_score(y, labels_g))\n",
    "print(\"Silhouette GMM:\", silhouette_score(X_PCA, labels_g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cec5b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Visualize clustering results. Using the best-performing model and configuration. \n",
    "# Show a grid plot with one row per cluster and five images per cluster.\n",
    "if best_score_k > best_score_g:\n",
    "    print(\"K MEANS\")\n",
    "    labels = labels_k\n",
    "    title = \"KMeans\"\n",
    "    K = best_params_k[\"n_clusters\"]\n",
    "else:\n",
    "    print(\"GMM\")\n",
    "    labels = labels_g\n",
    "    title = \"GMM\"\n",
    "    K = best_params_g[\"n_components\"]\n",
    "\n",
    "\n",
    "#NOT SURE I UNDErSTAND THIS\n",
    "#graphing the subplots\n",
    "fig, axes = plt.subplots(K, 5, figsize=(15, K*1.5))\n",
    "for cluster in range(K):\n",
    "    #first find the indices where the labels equal the cluster in K?\n",
    "    indices = np.where(labels == cluster)[0]\n",
    "    #then do random choicem accounting for when the  for when cluster has less than 5\n",
    "    num_images = min(5, len(indices))\n",
    "    chosen = np.random.choice(indices, num_images, replace=False)\n",
    "\n",
    "    \n",
    "    #reshape - \n",
    "    for n, index in enumerate(chosen):\n",
    "        ax = axes[cluster, n]\n",
    "        ax.imshow(X[index].reshape(28, 28), cmap=\"gray\") #reshape it back to original dimensions\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(f\"Img {index}\", fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.title(f\"Best clustering visualization â€“ {title}\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
